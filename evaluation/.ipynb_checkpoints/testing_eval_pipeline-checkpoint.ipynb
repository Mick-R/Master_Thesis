{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986287c0-30aa-47b1-8455-a8bfb1f1cf74",
   "metadata": {},
   "source": [
    "# LLM-Based Evaluation Pipeline\n",
    "\n",
    "This notebook presents an implementation of an LLM-Based Evaluation Pipeline for automated assessment of job listing quality.\n",
    "\n",
    "## Key Components\n",
    "1. **Evaluation Metrics**\n",
    "- Implements metrics derived from expert interviews and literature\n",
    "- Provides quantitative scoring across multiple quality dimensions with multiple techniques\n",
    "\n",
    "2. **Analysis Reporting**\n",
    "- Tracks efficiency through step counting\n",
    "- Documents pipeline performance across evaluation iterations\n",
    "- Generates detailed breakdowns of metric-specific assessments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa662c0d-a386-49af-ba74-25d07f31b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import dspy\n",
    "import openai\n",
    "\n",
    "import phoenix as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3659d18-c84f-4c6f-88a2-62e24c1923ac",
   "metadata": {},
   "source": [
    "## 1. Evaluation Metrics\n",
    "Example quality metrics:\n",
    "1. Clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c3572e-3f7f-4c7e-942b-6482f8e5763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLARITY_LLM_JUDGE_PROMPT = \"\"\"\n",
    "In this task, you will be presented with a job listing. Your objective is to evaluate the clarity \n",
    "of the job listing. A \"clear\" job listing is one that is well-structured, concise, easy to read, \n",
    "and directly communicates the necessary information without ambiguity or unnecessary complexity. \n",
    "An \"unclear\" job listing is one that deviates from the specified job, is vague, disorganized, overly complex, or difficult to understand.\n",
    "\n",
    "Your response should be a single word: either \"clear\" or \"unclear,\" indicating whether the listing is easy to understand. Do not include any other text or characters in your answer.\n",
    "\n",
    "After providing your response, you must write a detailed explanation justifying your reasoning. \n",
    "Avoid stating the final label at the beginning of your explanation. Your reasoning should focus on specific aspects of the job listing that affect clarity, such as grammar, organization, and conciseness.\n",
    "\n",
    "[BEGIN DATA]\n",
    "Input: {job_listing}\n",
    "Answer: {response}\n",
    "[END DATA]\n",
    "\n",
    "EXPLANATION: Provide your reasoning step by step, evaluating aspects like structure, language, and readability.\n",
    "LABEL: \"clear\" or \"unclear\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c2fcc7-9f2a-4096-9e5e-a7328a2bf6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clarity(output: str, input: str) -> bool:\n",
    "    if output is None:\n",
    "        return False\n",
    "    df = pd.DataFrame({\"query\": [input.get(\"question\")],\n",
    "                       \"response\": [output.get(\"final_output\")]})\n",
    "    response = llm_classify(\n",
    "        data=df,\n",
    "        template=CLARITY_LLM_JUDGE_PROMPT,\n",
    "        rails=[\"clear\", \"unclear\"],\n",
    "        model=eval_model,\n",
    "        provide_explanation=True\n",
    "    )\n",
    "    return response['label'] == 'clear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d2117-1fe8-43e2-a172-3495613f0095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
